# Performance Guide

## Performance Metrics

### Typical Performance Characteristics

| Metric | Small Project (<1k files) | Medium Project (1k-10k files) | Large Project (10k+ files) |
|--------|---------------------------|-------------------------------|----------------------------|
| **Indexing Speed** | 500+ files/second | 200-400 files/second | 100-200 files/second |
| **Search Latency** | <50ms | <100ms | <200ms |
| **Memory Usage** | 50-100MB | 100-500MB | 500MB-2GB |
| **Storage Size** | 1-10MB | 10-100MB | 100MB-1GB |
| **Startup Time** | <1s | 1-3s | 3-10s |

### Factors Affecting Performance

1. **File Size**: Larger files take longer to parse and embed
2. **Language Complexity**: Complex languages (C++, TypeScript) slower than simple ones (JSON, Markdown)
3. **Embedding Model**: Local models faster than cloud APIs
4. **Hardware**: CPU, RAM, and storage speed impact performance
5. **Network**: Cloud embedding providers depend on network latency

## Optimization Strategies

### 1. Embedding Model Selection

#### For Speed (Local Models)
```bash
# FastEmbed - Fastest local option
octocode config \
  --code-embedding-model "fastembed:all-MiniLM-L6-v2" \
  --text-embedding-model "fastembed:multilingual-e5-small"

# Optimized configuration
[embedding]
code_model = "fastembed:all-MiniLM-L6-v2"      # 384 dim, very fast
text_model = "fastembed:multilingual-e5-small"  # 384 dim, multilingual
```

#### For Quality vs Speed Balance
```bash
# SentenceTransformer - Good balance
octocode config \
  --code-embedding-model "sentencetransformer:microsoft/codebert-base" \
  --text-embedding-model "sentencetransformer:sentence-transformers/all-MiniLM-L6-v2"
```

#### For Maximum Quality (Cloud)
```bash
# High-quality cloud models (slower due to API calls)
octocode config \
  --code-embedding-model "voyageai:voyage-code-2" \
  --text-embedding-model "voyageai:voyage-3"
```

### 2. Indexing Configuration

#### Speed-Optimized Settings
```toml
[index]
chunk_size = 1000                # Smaller chunks process faster
embeddings_batch_size = 64       # Larger batches for efficiency
graphrag_enabled = false         # Disable for faster indexing

[search]
max_results = 20                 # Limit results for faster response
similarity_threshold = 0.2       # Higher threshold = fewer results
```

#### Quality-Optimized Settings
```toml
[index]
chunk_size = 2000                # Larger chunks for better context
embeddings_batch_size = 32       # Smaller batches for stability
graphrag_enabled = true          # Enable for relationship analysis

[search]
max_results = 50                 # More comprehensive results
similarity_threshold = 0.1       # Lower threshold = more results
```

### 3. Hardware Optimization

#### CPU Optimization
- **Multi-core**: Embedding generation uses multiple cores
- **CPU Type**: Modern CPUs with AVX2 support perform better
- **Recommended**: 4+ cores for optimal performance

#### Memory Optimization
```toml
[memory]
max_memories = 10000             # Adjust based on available RAM

[search]
max_results = 30                 # Reduce for lower memory usage
```

#### Storage Optimization
- **SSD**: Significantly faster than HDD for database operations
- **NVMe**: Best performance for large codebases
- **Network Storage**: Avoid for database files

### 4. Network Optimization (Cloud Providers)

#### Reduce API Calls
```bash
# Use local models when possible
octocode config --code-embedding-model "fastembed:all-MiniLM-L6-v2"

# Batch operations
octocode clear && octocode index  # Index all at once vs incremental
```

#### API Rate Limiting
```toml
[embedding]
# Adjust batch sizes for API limits
embeddings_batch_size = 16       # Smaller batches for cloud APIs
```

## Performance Monitoring

### Built-in Metrics

```bash
# Enable debug logging for performance metrics
RUST_LOG=debug octocode index

# Monitor indexing progress
octocode clear && octocode index 2>&1 | grep "Processed"

# Check database size
ls -lh ~/.local/share/octocode/
```

### Custom Monitoring

```bash
#!/bin/bash
# Performance monitoring script

echo "=== Octocode Performance Report ==="
echo "Date: $(date)"
echo

# Database size
echo "Database size:"
du -sh ~/.local/share/octocode/

# Index timing
echo "Indexing performance:"
time (octocode clear && octocode index)

# Search timing
echo "Search performance:"
time octocode search "authentication" > /dev/null

# Memory usage
echo "Memory usage during search:"
/usr/bin/time -v octocode search "database" > /dev/null 2>&1 | grep "Maximum resident"
```

## Troubleshooting Performance Issues

### Slow Indexing

**Symptoms**: Indexing takes much longer than expected

**Solutions**:
1. **Reduce chunk size**: `chunk_size = 1000`
2. **Use faster embedding model**: Switch to FastEmbed
3. **Disable GraphRAG**: Set `graphrag_enabled = false`
4. **Check disk space**: Ensure sufficient free space
5. **Monitor CPU usage**: Ensure no other heavy processes

```bash
# Quick fix for slow indexing
octocode config --code-embedding-model "fastembed:all-MiniLM-L6-v2"
octocode config --graphrag-enabled false
octocode clear && octocode index
```

### Slow Search

**Symptoms**: Search queries take several seconds

**Solutions**:
1. **Increase similarity threshold**: `similarity_threshold = 0.3`
2. **Reduce max results**: `max_results = 20`
3. **Check database corruption**: `octocode clear && octocode index`
4. **Optimize query**: Use more specific search terms

```bash
# Quick fix for slow search
octocode config --max-results 20
octocode config --similarity-threshold 0.3
```

### High Memory Usage

**Symptoms**: Octocode uses excessive RAM

**Solutions**:
1. **Reduce max memories**: `max_memories = 5000`
2. **Clear old data**: `octocode clear`
3. **Use smaller embedding models**: Switch to 384-dim models
4. **Limit search results**: `max_results = 20`

```bash
# Quick fix for memory issues
octocode config --max-results 20
octocode clear
octocode config --code-embedding-model "fastembed:all-MiniLM-L6-v2"
```

### API Rate Limiting

**Symptoms**: Errors from cloud embedding providers

**Solutions**:
1. **Reduce batch size**: `embeddings_batch_size = 8`
2. **Add delays**: Use local models for development
3. **Switch providers**: Try different cloud providers
4. **Use local models**: Switch to FastEmbed/SentenceTransformer

```bash
# Quick fix for rate limiting
octocode config --code-embedding-model "fastembed:all-MiniLM-L6-v2"
octocode config --text-embedding-model "fastembed:multilingual-e5-small"
```

## Benchmarking

### Standard Benchmark

```bash
#!/bin/bash
# Octocode benchmark script

PROJECT_PATH="/path/to/test/project"
cd "$PROJECT_PATH"

echo "=== Octocode Benchmark ==="
echo "Project: $PROJECT_PATH"
echo "Files: $(find . -type f -name "*.rs" -o -name "*.py" -o -name "*.js" | wc -l)"
echo

# Clear previous data
octocode clear

# Benchmark indexing
echo "Indexing benchmark:"
time octocode index

# Benchmark search
echo "Search benchmark (10 queries):"
queries=("authentication" "database" "API" "error handling" "configuration" "testing" "middleware" "validation" "logging" "security")

for query in "${queries[@]}"; do
    echo -n "Query '$query': "
    time octocode search "$query" > /dev/null
done

# Database size
echo "Final database size:"
du -sh ~/.local/share/octocode/
```

### Performance Comparison

| Configuration | Indexing (1000 files) | Search Latency | Memory Usage | Quality Score |
|---------------|----------------------|----------------|--------------|---------------|
| **FastEmbed** | 30s | 50ms | 200MB | 7/10 |
| **SentenceTransformer** | 60s | 80ms | 400MB | 8/10 |
| **Cloud (Jina)** | 120s | 100ms | 300MB | 9/10 |
| **Cloud (Voyage)** | 150s | 120ms | 350MB | 9.5/10 |

## Best Practices

### Development Workflow

1. **Use local models** during development
2. **Enable cloud models** for production/final indexing
3. **Regular cleanup**: `octocode clear` periodically
4. **Monitor performance**: Track indexing and search times

### Production Deployment

1. **Optimize for your use case**: Speed vs quality tradeoff
2. **Monitor resource usage**: CPU, memory, storage
3. **Plan for scaling**: Consider hardware requirements
4. **Backup strategy**: Regular database backups

### Configuration Templates

#### Development (Speed Focus)
```toml
[embedding]
code_model = "fastembed:all-MiniLM-L6-v2"
text_model = "fastembed:multilingual-e5-small"

[index]
chunk_size = 1000
graphrag_enabled = false

[search]
max_results = 20
similarity_threshold = 0.3
```

#### Production (Quality Focus)
```toml
[embedding]
code_model = "sentencetransformer:microsoft/codebert-base"
text_model = "sentencetransformer:sentence-transformers/all-mpnet-base-v2"

[index]
chunk_size = 2000
graphrag_enabled = true

[search]
max_results = 50
similarity_threshold = 0.1
```

#### Large Scale (Balanced)
```toml
[embedding]
code_model = "fastembed:BAAI/bge-small-en-v1.5"
text_model = "fastembed:multilingual-e5-small"

[index]
chunk_size = 1500
graphrag_enabled = true

[search]
max_results = 30
similarity_threshold = 0.2

[memory]
max_memories = 50000
```
